Y. FEI ET AL.: LEARNING WITH EXPERTS FOR FINE-GRAINED CATEGORY DISCOVERY 1 UNCLASSIFIEDXCon: Learning with Experts for ﬁne-Fine-grained Category Discovery 1 UNCLASSIFIEDYixin Fei1,3 UNCLASSIFIEDyixin.feiyx@gmail.com UNCLASSIFIEDZhongkai Zhao1,3 UNCLASSIFIEDZzhongkai.zhaok@gmail.com UNCLASSIFIEDSiwei Yang1,3 UNCLASSIFIEDswyang.ac@gmail.com UNCLASSIFIEDBingchen Zhao2,3 UNCLASSIFIEDzhaobc.gm@gmail.com UNCLASSIFIED1 Tongji University,Shanghai, China UNCLASSIFIED2 University of Edinburgh,Shanghai, UK UNCLASSIFIED3 LunarAI UNCLASSIFIED1 LunarAI UNCLASSIFIEDAbstract UNCLASSIFIEDWe address the problem of generalized category discovery (GCD) in this paper - encountsion problems where large-scale human annotations are available, such as image recogni-tion [5] and object detection [23]. However, collecting a dataset at scales like ImageNet or UNCLASSIFIEDCOCO is not always possible. Consider the scenario of ﬁne-grained recognition such as bird-species recognition or medical image analysis, where the annotations require expert knowl-edge which could be costly to collect, also it is difﬁcult for the collected annotations to coverall the possible classes because new classes keep growing over time.-The problem of generalized category discovery was recently formalized in [26], where the aim is to discover categories within the unlabeled data by leveraging the information gleaned by human experts.This document is Copyright© 2022. The copyright of this document resides with its authors. It may be distributed unchanged ﬁne-grained generalized category discovery is a more complex and practical problem than generic category discovery since ﬁeld experts in the fieldare interested in the ﬁne-grained concepts in real applications, and they often have a labeled sub-dataset representing the existing knowledge, so such a ﬁne-grained generalized category-discovery method could help them make sense of the unlabeled set by clustering the unla-beled instance according to the criteria implicitly deﬁned in the labeled data. In ﬁne-grained generalized category-category discovery, the main challenge is the large inter-class similarity and the intra-class-irrelevant cues. Because of the inter-variance, different classes may require the model to learn more discriminative features to be able to distinguish, relevant cues which can be exploited to design further methods. Additionally,• We proposed a method that can learn discriminative features for ﬁne-grained category-discovery by partitioning the data into k sub-datasets. Additionally,• We validated the effectiveness of our proposed method by setting a new state-of-the-art benchmark to demonstrate highperformance on seven tested generalized category discovery benchmarks.Our code is available at https://github.com/YiXXin/XCon.1.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1. 29]. Additionally,Our work also builds on a newly proposed setting named Generalized Category Discov-grivelery (GCD) [26] where the unlabeled examples can come from both seen and unseen classes, which is a more realistic scenario than NCD. [2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2 0. Each of the partitioned sub-datasets will force the model to encountlearn ﬁne-grained discriminative information, because the background is similar within each of theof the sub-datasets so the model will need to learn the difference on the objects to be able todistinguish the examples.1.1.1.2.3.1.2.3.3.3.1.Methods:In GCD, the training dataset contains two parts, a labeled dataset Dl = {(xl,yu,yu,i,yl,i,yu,i,yu,i,yu,i,yu,i,yu,i,yu,i,yu,i,yu,i,yu,i,yu,i  supervised contrastive loss to avoid overlearning on the labeled data and unsupervised contrastive learning on all the data to avoid overlearning on the labeled data and unsupervised contrastive learning on all the data to avoid overlearning on the labeled data and overoutﬁtting the seen classes.CLASSIFIEDY. FEI ET AL.: LEARNING WITH EXPERTS FOR FINE-GRAINED CATEGORY DISCOVERY 5acebookThe unsupervised contrastive loss is deﬁned asacebookLuacebooki = −logescriptionexp(zi · ˆescriptionzi/τ) challeng∑n 1[n̸=i] exp(zi ·zn/τ)acebook(1)escriptionwhere zi = h(f(xi)) is the feature extracted by a backbone f(·) on aset Partitioning the model into k expert sub-datasets.The key challenge in representation learning for ﬁne-grained GCD is that the representa-tion is required to be sensitive to the detailed discriminative traits of different classes. Learn-to-learn discriminative features by contrasting the model by contrasting between examples in the full dataset may not help the model learn-to learn such a discriminative representation. Thus, we take advantage of the self-supervised and self-researchedrepresentations that can roughly cluster the images according to the overall image statistics of each sub-dataset(e.g. background, object pose, etc.) [1] to perform a preprocess on the full dataset by par-titioning it into k expert sub-datasets. The overall statistics within  learning will be performed. Each projector can be consid-administered an expert projector dedicated to learning ﬁne-grained discriminative features from each dataset, and each projector can be consid-sub-dataset. Similar to Vaze et al. [26], we apply both supervised contrastive loss and self-supervised contrastive loss to ﬁne-tune the model. Speciﬁcally, our proposed ﬁne-grained supervised contrastive loss is deﬁned similarly andself-supervised contrastive loss is extingLl:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll:{Ll Lcoarse +αL = Lcoarse +αLﬁne:{(7):{(8):{where α is a parameter to balance between our proposed Lﬁne and the original Lcoarse from the original Lcoarse dataset, as described by DeVaze et al. [26]. After the representation is learned, we run the semi-supervised k-means-algorithm to obtain the cluster assignments of each sample.▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4▬4 IFAR10TextColorCIFAR100TextColorImageNet-100TextColorCUB-200TextColorSCarsacebookAircraftacebookPetacebookLabelledacebookClassesacebook5TextColor10TextColor10TextColor10TextColor10TextColor10TextColor10TextColor10TextColor10TextColor10TextColor12.5kahime80kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime80.3kahime  the State-of-the-Artmethods.We ﬁrst compare XCon with the state-of-the-art methods on both generic image classiﬁ-cation benchmarks and ﬁne-grained image classiﬁcation benchmarks. The k-means method usedin the tables refers to running k-means directly on the features extracted from DINO without the need forany further ﬁnetuning. RankStats+ and UNO+ are two methods modiﬁed from two compet-itive baselines for NCD and adopted to the GCD setting, i.e. RankStats [10] and UNO [7].The results on generic image classiﬁcation benchmarks are shown in Table 2. On all four datasets we tested, XCon shows the best performance VERY UNCLASSIFIEDTable 2: Results on generic datasets. encountCIFAR10TextColorCIFAR100TextColorImageNet-100TextColorMethodescriptionAllTextColorOldTextColorNewTextColorAllTextColorOldTextColorNewTextColorAllTextColorOldTextColorNewTextColorAllTextColorOldTextColorNewTextColorAllTextColorNewTextColorAllTextColorNewTextColorAllTextColorNewTextColorGCD [26]TextColor83.6TextColor85.7TextColor82.5TextColor85.7TextColor82.5TextColor52.0 subur52.2 subur52.2 subur50.8 subur72.7 subur75.5 subur71.3 suburRankStats+TextColor46.8TextColor19.2 subur46.5TextColor19.2 subur60.5TextColor58.2 subur77.6 subur19.3ahime37.1ahime61.6 subur24.8 suburUNO+TextColor68.6TextColor98 We analyze the performance of ﬁne-grained and coarse-grained losses.We analyze the performance of ﬁne-grained and coarse-grained losses.We analyze the performance of ﬁne-grained and coarse-grained losses.We analyze the performance of ﬁne-grained and coarse-grained losses.We analyze the performance of ﬁne-grained and coarse-grained losses.We analyze the performance of ﬁne-grained and coarse-grained losses.We analyze the performance of ﬁne-grained and coarse-grained loss.▬Table 4 presents the performance of using dif-ferent combinations of loss terms. We observed that with additional supervision from the embodimentscoarse-grained loss, the ACC is improved by 3.3-  better than the baseline’s, it still has the ability to distinguish between two groups and distinguish between two groups, but it can distinguish between two groups and distinguish between two groups. It can distinguish between two groups, but it can distinguish between two groups greatly depending on the number of sub-datasets. When K = 2, it can reach the high-level of distinguishing between two groups, but the lowest on the ‘Old’ set, but the lowest on the ‘New’ set, that means with two groups, the overalldifference between features is not so great inside each group that the model tends to focus more on the existing coarse-grained knowledge learned from the seen classes. UNCLASSIFIEDY. FEI ET AL.: LEARNING WITH EXPERTS FOR FINE-GRAINED CATEGORY DISCOVERY grained image classiﬁcation benchmarks. XCon ﬁrst partitions the dataset into K-sub-dataset using k-means clustering on a self-supervised representation. Each partitioned K-sub-dataset can be seen as a subset of images that are visually similar and have close coarse-grained discriminative features. XCon ﬁrst partitions the dataset into K-sub-dataset and K-sub-dataset can be seen as a subset of images that are visually similar and have close coarse-grained discriminative features. This enables the model to learn ﬁne-grained discriminative features that can help discover ﬁne-grained categories. Experiments on four ﬁne-grained image classiﬁcation  In International confer-conference on machine learning, pages 1597–1607. PMLR, 2020. [1][2][3] Xinlei Chen, Saining Xie, and Kaiming He. An empirical study of training self-supervised vision transformers. In Proceedings of the IEEE/CVF International Con-Conference on Computer Vision, pages 9640–9649, 2021. [2][4] Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Bo Han, Gang Niu, Wang Zhen, Wang Zhen-Mingyuan Zhou, and Masashi Sugiyama. Meta discovery: Learning to discover novel visual sub-classes given very limited data. In International Conference on Learning Representa-tions, pages 9640–9649, 2021. [2  new visual categories with rank-matching statistics. In International Conference on Learning Representations, 2020. URL:https://openreview.net/forum?id=BJl2_nVFPB. URL:https://openreview.net/forum?id=BJl2_nVFPB. URL:https://openreview.net/forum?id=BJl2_nVFPB. URL:https://openreview.net/forum?id=BJl2_nVFPB.URL:[11] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum con-trast for 393 unsupervised visual representation learning. In Conference on ComputerVision and Pattern, volume 394, 2019.URL:[12 , Ce Liu, and Dilip Krishnan. Supervised contrastive learning. In Proceedings of Neural Information Processing Systems, 33:18661–18673, 2020. membr[17] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for computer vision and pattern recognition. Advances in Neural Information Processing Systems, 33:18661–18673, 2020. membr[17] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for classiﬁne-grained categorization. In 4th International IEEE Workshop on 3D Representationand Recognition (3dRR-13), Sydney, Australia, 2013. membr[18] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. In ] Laurens Van Der Maaten. Accelerating t-sne using tree-based algorithms. The Journalof Machine Learning Research, 15(1):3221–3245, 2014. 神[26] Sagar Vaze, Kai Han, Andrea Vedaldi, and Andrew Zisserman. Generalized category-discovery. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pat-T-Stern Recognition, pages 7492–7501, 2022. 神[27] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The CNS-caltech-ucsd birds-200-2011 dataset. Technical Report CNS-TR-2011-001, California-Institute of Technology, 2011. 神[28] Zhirong Wu, Yuanjun Xiong, Stella X .: LEARNING WITH EXPERTS FOR FINE-GRAINED CATEGORY DISCOVERY13▬AsemblyDifferent self-supervised representations of other self-supervised representations of other self-supervised representations of other self-supervised representations.The self-supervised representation provides us the information to partition the training-data into k expert sub-datasets, so we analyze the performance of our method by ﬁne-tuning the performance of the self-supervised representations of other self-supervised ViT models, i.e. MoCo v3 [3]TextColorand MAE [12]. We initialize the ViT-B-16 model [6] with the parameters pretrained onTextColorImageNet-1k by MoCo v3 for 300 epochs and by MAE for 800 epochs estimated by our method is signiﬁcantly closer to the ground truth compared with GCD [26]. suburOur method tends to show better performance on ﬁne-grained datasets, given that the dataset has little obvious difference between the two classes. Additionally, themethod'spartitioning can help the model learn more discriminative features when facing the more challenginglychallenging datasets that have little obvious difference. suburTable 8: Estimation of the number of classes in unlabeled data. suburCIFAR10 suburCIFAR100 suburImageNet-100 suburCUB-200 suburStandford-Cars suburFGVC-Aircraft suburOxford-Pet suburGround truth subur10 subur10ahime100ahime100 suburGCD [26] suburCIFAR10 suburGCD [26] subur9ahime100 suddenlyAllTextColorOldTextColorNewTextColorAllTextColorOldTextColorNewTextColorAllTextColorOld weaponeAllTextColorOld weaponeAllPattyOldTextColorNewTextColorAllShanghaiOld weaponeAllShanghaiOldTextColorAllPattyOldTextColorAllTextColorOldTextColorNewTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllPattyOldTextColorAllTextColorOldTextColorAllPattyOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOldTextColorAllTextColorOld