Y. FEI ET AL.: LEARNING WITH EXPERTS FOR FINE-GRAINED CATEGORY DISCOVERY 1                XCon: Learning with Experts forFine-grained Category Discovery. The copyright of this document resides with its authors. The features learned by our method could cluster the images based on the correct cues, e.g., background and object pose. We present a novel method called Expert-Contrastive Learning (XCon) to help experts discover novelconcepts within an unlabeled dataset. We show a clear improved performance over the previous best methods, demonstrating the effectiveness of our method. It is assumed that the labeled data contains similar yet distinct yet distinct classes. The labeled data collected by human experts can be seen as an implicit criterion of classes which can be learned by the model. Novel Category Discovery (NCD) aims to discover new object categories by transferring knowledge learned from a set of relevant but different seen classes. In NCD, different classes may require the model to learn more discriminative features to distinguish, e.g., two different birds could only differ in the beak. We observed that an unsupervised representation (e.g. DINO) could cluster the data based on classirrelevant cues such as the object pose or the background, see the left part of Fig. 1. Based on this observation, we proposed a simple yet effective method to boost the performance of generalized category discovery on ﬁne-grained data named Expert Contrastive Learning                (XCon). In our proposed XCon method, we partition the data into k expert sub-datasets by directlyperforming k-means clustering on self-supervised representations. Contrastive learning has been showing to be effective for learning representations. We proposed a simple method that partitions the dataset into k sub-datasets by using k-means on self-supervised features. The goal of GCD is to learn a model to categorize the instances in Du by leveraging the information from Dl. Compared to previous GCD methods with contrastivelearning [26], our method shows clear performance improvements. In the next section, we brieﬂy review the method proposed in Vaze et al. [26] for GCD, which consists of two parts, representation and class assignment. For representation, we perform unsupervised contrastive learning on all the data. For class assignment, we performed supervised contrastiveLearning on the labeled data and unsuperivelearning on the unlabeled data. The key challenge in representation learning for GCD is to be sensitive to the detailed discriminative traits of different classes. We take advantage of the self-supervised.representations that can roughly cluster the images according to the overall image statistics. We partition the full dataset into k expert sub-datasets, each of which will be used for ﬁne-grained category discovery later. We use a set of projectors to project over- the-top global statistics to each corresponding Y project. We apply both supervised contrastive loss and self-unearthed contrastive learning to the model. We also use the semi- supervised k-means method for class assignments. The model can be consid-ered an expert projector dedicated to learning discriminating features from each sub-sub- dataset. -supervised contrastive loss is the combination of two loss types. We evaluate our method on both generic image classiﬁcation datasets and ﬁne-grained datasets. We split the training data into a labeled and unlabeled set. We employ the clustering accuracy (ACC) on the unlabeling set to mea-privilegedsure the performance. The evaluation metric is deﬃned as below the maxACC metric. We use CIFAR-10/100/100 and ImageNet- grotesque100 as the generic image classesi-cation datasets. Our dataset splits in two: a labeled set and an unlabelED set with 50% images from the seen class set and 50% from the unseen one. We also evaluate the performance of the image clas-reprehensiblesi-si-situational datasets. We use ViT-B-16 as the backbone of our method. We train the model with the parameters pretrained by DINO [1] on ImageNet. The results on generic image classiﬁcation benchmarks are shown in Table 2. On all datasets we tested, XCon shows the best performance on ‘All’, showing that our method could improve upon previous works. XCon achieves comparable results with other methods on the other subsets as ‘Old’ and ‘New’. It should be noticed that XCon’s best performance is achieved by naively running a k-means on DINO features. This suggests that the original features can already represent the unlabeled categories well, and the XCon method achieves the closest performance compared to this baseline. We compare XCon with the state-of-the-art methods. XCon can consistently outperform the baseline(α = 0) with different α, showing the robust effectiveness of our method. XCon can reach the high-varies greatly depending on the number of sub-datasets. When K = 0, the ‘New’ set is consistently. better than the baseline’s, but the lowest on the “Fine-grained” set. “New” means that with two groups, the overalldifference between the overall features is not so great so that the model tends to focus more on the existing coarse-Grained knowledge.” “We observed that with additional supervision from the. tightly co-ordinated loss, the ACC is improved by 3.3-4.0% on CUB-200 and 15.4-28.5% on Standford Cars” We propose XCon to address the problem of generalized category discovery with ﬁne-grained image classiﬁcation benchmarks. XCon partitions the dataset into Ksub-dataset using k-means clustering on a self-supervised representation. Each partitioned sub- dataset can be seen as a subset of images that are visually similar. This contrastive learning will force the model to learn discriminative features that can help discover categories. The author would like to acknowledge compute support from LunarAI10Y. We also acknowledge the support of LunarAI 10Y and the University of California, San Diego. We are the first to publish a paper on this topic in an open-access journal, the Journal of Computer Vision and Pattern Recognition (JCVPR). For confidential support, call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org. -scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255. An image is worth 16x16 words: Transformers for image recognition at scale. In Proceedings of the IEEE/CVF International. Conference on Computer Vision, pages 8401–8409, 2019. A uniﬁed objective for novel class discovery. In International Conference on Learning Representations, 2020. The method for hungarian method for the assignment problem for the Naval. researchlogistics quarterly 2(1-2):(83–97):(1) 2(2) 3(3) 4(4) 5 (5) 6 (6) 7 (7) 8 (8) 9 (9) 10 (10) 11 (11) 12 (12) 13 (13) 14 (14) 15 (15) 16 (16) 17 (17) 18 (18) 19 (19) 20 (20) 21 (21) 22 (2) 23 (3) The self-supervised representation provides us the information to partition the training data into k expert sub-datasets. We analyze the performance of our method by �ne-tuning different pretrained representations of other self- supervised models. We observe that the best performance on the clustering based on the class data is better than the other two on the two other two CUB200-200 and CUB 200-200-2000 data sets. We also show that with the pretrained parameters on the ViT-B-16 model [6] we get better results than with the other parameters on MoCo-Co v3.1-16 by 800% onStandford DINO. We conclude with the conclusion that our method is better at clustering than other methods on the DINO data set by 800%. We use the method in [26] to estimate the number of classes in an unlabeled dataset by leveraging the information of the labeled dataset. Our method tends to show better performance on ﬁne-grained datasets. We further ablate the components of contrastive loss in Table 11. We find that only with supervised contrastive. loss, i.e. λ = 0, the ACC drops 21.5 −23.6% on CUB-200 and. 22.2 −46.2% on Standford-Cars. We report the results on generic. image classiﬁcation benchmarks in Table 9 and the results in Table 10. We conclude that our method is also promising under the more realistic condition. of the ‘unsupervised. contrastive’ condition. With the balanced parmeter λ = 0.35 is necessary and can reach the best performance. with the balancedParmeter =0.35 and with the balance parmeter = 1.0 is necessary to achieve 0.1 is necessary for 0.2 is necessary. The study of contrastive loss was carried out on the Stanford-CUB-200 car. The results of the study were published in the Journal of the American Chemical Society (JACS) in 2007. The JACS report was published in 2008 and has been cited in the journal of the Chemical Society of America (CSA) and the American Society of Chemical Engineers (ASCE) (2008). The JSCS has published a report on the results of its study on contrastive losses in the CUB 200 car in 2008.