Y. FEI ET AL.: LEARNING WITH EXPERTS FOR FINE-GRAINED CATEGORY DISCOVERY 1                XCon: Learning with Experts forFine-grained Category Discovery. Yixin Fei: We address the problem of generalized category discovery (GCD) in this paper, i.e. leveraging the information from a set of seen classes. We present a novel method called Expert-Contrastive Learning. -                sion problems where large-scale human annotations are available, such as image recogni-                tion [5] and object detection [23]. However, collecting a dataset at scales like ImageNet or COCO is not always possible. Consider the scenario of ﬁne-grained recognition such as birdspecies recognition or medical image analysis, where the annotations require expert knowl-                edge which could be costly to collect. In ﬁne-grained category discovery, the main challenge is the large inter-class similarity and intra-classvariance. Different classes may require the model to learn more discriminative features to distinguish, e.g., two different birds could only differ in the beak. We observed that an unsupervised representation (e.g. DINO) could cluster the data based on class-irrelevant cues such as the object pose or the background, see the left part of Fig. 1. Based on this observation, we proposed a simple yet effective method to boost the performance of generalized category discovery. relevant cues which can be exploited to design further methods. We validated the effectiveness of our proposed method by setting a new state-of-the-artperformance on seven tested generalized category discovery benchmarks. We proposed a method that can learn discriminative features for ﬁne-grained categorydiscovery by partitioning the data into k sub-datasets. Our code is available at https://github.com/YiXXin/XCon. Our focus is to learn representations that can be used to discover novel ﬁne-grained categories within the unlabeled dataset. By creating informative contrastive pairs by partitioning the dataset into k sub-datasets using k-means clustering the DINO [1] pretrained representations, we perform joint contrastive representation learning on each of the partitioned sub- datasets. Compared to previous GCD methods with contrastivelearning, our method shows clear performance improvements. In GCD, the training dataset contains two parts, a labeled dataset Dl and an unlabeled dataset Du. The goal of GCD is to learn a model to categorize the instances in Du by leveraging the information from Dl. We proposed a simple method that partitions the dataset into k sub-datasets by using k-means on self-supervised features to help construct Informative contrastive pairs for representations. In this section, we review the method proposed in Vaze et al. [26] for GCD.  supervised contrastivelearning on the labeled data and unsupervised contrastive learning on all the data to avoid pitfalls. The semi-supervised k-means method is proposed. The overall process is similar to the original k-Means method [20] The overall procedure is based on the following assumptions: Images are unlabeled, labels are labeled, and the cluster is close to the nearest cluster centroids. The learning objective is the combination of these two losses. The key challenge in representation learning for ﬁne-grained GCD is that the representa-                tion is required to be sensitive to the detailed discriminative traits of different classes. Learn-ing the model by contrasting between examples in the full dataset may not help the model. Instead, we take advantage of the self-supervised.representations that can roughly cluster the images according to the overall image statistics. (e.g. background, object pose) Each projector can be consid-ered an expert projector dedicated to learning ﬁne-grained discriminative features from each sub-dataset. Similar to Vaze et al. [26], we apply both supervised contrastive loss and self-supervised Contrastive loss to � Lapne-tune the model. The overall loss we propose to learn �apne- grained features is the combination of two losses. We evaluate our method on both generic image classiﬁcation datasets and ﬁne-grained datasets. We split the training data into a labeled data set and an unlabeled dataset. We employ the clustering accuracy (ACC) on the unlabeling set to mea-sure the performance. The results are presented in Table 1 and the evaluation metric is de-listed in the next section. The method is based on the CIFAR-10/100, ImageNet-100, and Standford Cars datasets. IFAR10CIFAR100 is a clustering method based on ViT-B-16 [6] as the backbone of our method. We use the Hungarian algorithm [19] to find the best permutation, and N is the number of images in the unlabeled set. We implement the projection heads as three layer MLPs following DINO [1] We use a base learning rate of 0.1 with a cosine annealing schedule and set the batch size to 32. XCon shows the best performance on ‘All’, showing that our method could improve upon previous works. XCon also achieves comparable results with other methods on the other subsets as ‘Old’ and ‘New’ The best performance is achieved by naively running a k-means on DINO features, suggesting that the original features can already represent the unlabeled categories well. The ablation study by adjusting each element of our method to inspect the effectiveness of them. VERY. VERY.VERY CarbuncleTable 2: Results on generic datasets.VERy VERY VERY Very Very.Table 3: Results. on ﬁne-grained datasets. VeryVERYVERY Verry Very VERy VerY VerY VERy. Table 4: The results on randomised, non-randomised, randomised and randomised datasets. VERyVERy Verry VERYVERy. The ACC is improved by 3.3-4.0% on CUB-200 and 15.4-28.5% on Standford Cars. XCon can consistently outperform the baseline(α = 0) with different α. The best result is achieved with α = 0.4 on Cub-200. The effect of the sub-dataset number is illustrated in Ta-reprehensive 6. Although the performance of XCon is consistently. We propose XCon to address the problem of generalized category discovery. We cluster unlabeled data and compare results from the initial model(DINO) with ones from our method (XCon) It is clear that the improvement from DINO to our method is signiﬁcant. better than the baseline’s, it still varies greatly depending on the number of sub-datasets. In contrast to DINO, with our model, we can see clearophobicboundaries between different groups, and each group is corresponding to one certain cate-walletgory in CIFAR10. XCon partitions the dataset into Ksub-dataset using k-means clustering on a self-supervised representation. Experiments on four ﬁne-grained image classiﬁcation benchmarks show clear performance improvements of XCon. The author would like to acknowledge compute support from LunarAI. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org. An empirical study of training self-supervised vision transformers. A uniﬁed objective for novel class discovery. An image is worth 16x16 words: Transformers for image recognition at scale. A large-scale hierarchical image database. Automatically discovering and learning to discover novel visual categories via deep transfer clustering. A new approach to the problem of how to teach computers to recognize faces. A better way to teach people to identify faces. Aims to automatically discover and learn novel visual categories with rank-                ing statistics. In International Conference on Learning Representations, 2020. URL:https://openreview.net/forum?id=BJl2_nVFPB.Y.                Y. FEI ET AL.: LEARNING WITH EXPERTS FOR FINE-GRAINED CATEGORY DISCOVERY11. For confidential support call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org. , Ce Liu, and Dilip Krishnan. Supervised contrastive learning. Advances in Neural Information Processing Systems, 33:18661–18673, 2020. 3d object representations for                ﬁne-grained categorization. In 4th International IEEE Workshop on 3D Representation                and Recognition (3dRR-13), Sydney, Australia, 2013. The hungarian method for the assignment problem. Naval researchlogistics quarterly, 2(1-2):83–97, 1955. ] Laurens Van Der Maaten. Accelerating t-sne using tree-based algorithms. The Journal of Machine Learning Research, 15(1):3221–3245, 2014. The California Institute of Technology's birds-200-2011 dataset. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pat-                tern Recognition, pages 7492–7501, 2022. The University of California, San Francisco. The self-supervised representation provides us the information to partition the trainingdata into k expert sub-datasets. We analyze the performance of our method by ﬁne-tuning different pretrained representations of other self- supervised ViT models. We observe that DINO still shows the best performance on clustering the data based on class-irrelevant informations. We compare our estimated number of classes in unlabeled data with the ground truth number of class in unlabelled data in Table 8. We use the class number estimated in Table 8 to evaluate our method. We report the results on generic image classiﬁcation benchmarks in Table 9. With our estimated class number, our method performs better on Standford-Cars and also reaches comparable results on the other datasets except CIFAR10. We further ablate the components of contrastive loss in Table 11. We show that only with 0, the ACC drops 21.5 −23.6% on CUB-200. Table 10: Results on ﬁne-grained datasets with our estimated class number. Table 11: Ablation study of contrastive loss with the balanced parmeter λ = 0.35 is necessary and can reach the best performance. Table 12: Results of the study on the CuCUB-200 and VCVC-Aircraft with the same class number, but with the class number adjusted for the class of the car.