we present a novel method called Expert-Contrastive Learning (XCon) to help the model to learn fine-grained discriminative features from the images. deep learning models have achieved super-human performance on many computer vi- sion problems. our method is based on the results of deep learning experiments on fine-grained datasets. it is hoped that deep learning will be able to improve the accuracy of deep learning models. the problem of generalized category discovery was recently formalized in [26]. aim is to discover categories within the unlabeled data by leveraging the information  2022. the copyright of this document resides with its authors. it may be distributed unchanged freely in print or electronic forms. cs.v:2208.01898v1 [cs.CV] 3 Aug 2022 2 Y. FEI ET AL. field experts are interested in the fine-grained concepts in real applications. we propose a method that can learn discriminative features for fine-grained category discovery. we partition the data into k expert sub-datasets by directly performing k-means clustering on self-supervised representations. the method can be used as a strong prior for the next learning phase, if the data is not labeled, we say. our code is available at https://github.com/YiXXin/XCon. NCD aims to discover new object categories by transferring the knowledge learned from a set of relevant but different seen classes. a common three- step learning pipeline is proposed in RankStat [9], where the representation is first learned with self-supervision on all the data and then fine-tuned on the labeled data. our method is effective for learning representations using instance discrimination. it pushes negative examples away from each other and pulls positive examples closer. compared to previous methods with contrastive learning, our method shows clear performance improvements. compared to previous methods with contrastive learning, our method shows clear performance improvements. back to mail online home. back to the page you came from and are you familiar with this article? share your thoughts with cnn ireport. the goal of GCD is to learn a model to categorize the instances in Du. self-supervised ViT features [1] could be a good initialization for representation learning. k-means on self-supervised features could help construct informative contrastive pairs for representations. the method proposed in vaze et al. [26] for GCD consists of two parts, representation learning and class assignment. Fig. 2. learn- ing the model by contrasting between examples in the full dataset may not help the model to learn such a discriminative representation. we take advantage of the self-supervised representations that can roughly cluster the images according to the overall image statistics. the model will naturally learn fine-grained discriminative features to distin- guish between classes. the final learning objective is the combination of these two losses Lcoarse = (1)  iBU BL Lu i + we denote the whole training set as D = (xi,yi). the feature vi = f(xi) is extracted from each image xi. the whole D is clustered into K sub-datasets D1,D2,,DK using k-means. each sub-dataset contains similar images and will be used for fine-grained category discovery later. vi are two views of one same image through data augmentation, and  is the temperature parameter. the overall loss we propose to learn fine-grained features is the combination of two losses. we evaluate our method on both generic image classification datasets and fine- grained datasets. we split the training data into a labeled image and run the semi-supervised k-means algorithm to obtain the cluster assignments of each sample. d dataset and an unlabeled dataset by first dividing all classes equally into a seen class set and an unseen one. then sampling 50% images from the seen classes as unlabeled data so that the labeled set Du contains images from both seen classes and unseen classes. the evaluation metric is defined as below pP(yu) 1 N N  i=1 1yi = p(  yi) (8) Y. the batch size for the entire training dataset is set to 256 and the batch size of all the sub-datasets is set to 32. for the ImageNet dataset, all models are trained for 60 epochs while for other datasets, models are trained for 200 epochs. for a fair comparison with existing methods, we use the same semi-supervised k-means method as [26] to do the evaluation. XCon 96.0 97.3 95.4 74.2 81.2 60.3 77.6 93.5 69.7 GCD [26] 91.5 97.9 88.2 73.0 76.2 66.5 74.1 89.8 66.3 XCon 52.1 54.3 51.6 24.2 28.3 61.8 12.1 26.6 40.3 56.4 32.2 - - - - UNO+ 35.1 49.0 28.1 35.5 70.5 18.6 40.3 56.4 32.2 combining the fine-grained and coarse-grained losses achieves the best performance. the best result is achieved with  = 0.4 on CUB-200 and with  = 0.2 on Standford Cars. although the performance of XCon is consistently better than the baseline, it still varies greatly depending on the number of sub-datasets. XCon can consistently outperform the baseline( = 0) with different weight . we visualize the feature spaces with TSNE on CIFAR10 by mapping the features into two dimensions for a more direct qualitative analysis. the improvement from DINO to our method is significant. with our model, we can see clear boundaries between different groups, and each group is corresponding to one certain cate- gorical class. XCon first partitions the dataset into K sub-dataset using k-means clustering on a self-supervised representation. Xinlei Chen, Saining Xie, and Kaiming He. An empirical study of training self- supervised vision transformers. in Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9640–9649, 2021. Xia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. Kai Han, Sylvestre-Alvise Rebuffi, Sebastien Ehrhardt, Andrea Vedaldi, and Andrew Zisserman. Learning to discover novel visual categories via deep transfer clustering. in Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9284–9292, 2021. [12] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Yanghao Li, Piotr Dollár, and [16] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan. Supervised contrastive learning. Advances in Neural Information Processing Systems, 33:21798–21809, 2020. [18] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine- [22] Omkar M Parkhi, Andrea Vedaldi, and Andrew Zisserman. Cats and dogs. In 2012 IEEE conference on computer vision and pattern recognition, pages 3498–3505. [29] Bingchen Zhao and Kai Han. Novel visual category discovery with dual ranking statis- tics and mutual knowledge distillation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7492–7501, 2022. [32] Zhun Zhong, Linchao Zhu, Zhiming Luo, Shaozi Li, Yi Yang, and Nicu Sebe. open-mix: reviving known knowledge for discovering novel visual categories in an open world. [32] Zhenglong Sun, Zhenglong Sun, and Chang Wen Chen. self-supervised learning for fine-grained category discovery. [32] Zhun Zhong, Enrico Fini, Subhankar Roy, Zhim we use the method in [26] to estimate the number of classes in unlabeled data. on Standford-Cars and FGVC-Aircraft, the number of classes estimated by our method is significantly closer to the ground truth compared with GCD. with our estimated class number  Cu, our method performs better on Standford-Cars and also reaches comparable results on the other five datasets except CIFAR10. 46.6% on Standford-Cars, which means the combination of supervised contrastive 14Y. FEI ET AL. Table 9: Results on generic datasets with our estimated class number. known Cu CIFAR10 CIFAR100 ImageNet-100 All Old New All Old New All Old New All Old New 0 29.6 30.2 29.3 10.8 12.5 10.0 0.35 51.8 53.8 50.8 41.0 59.1 32.2